{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "bbfbd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a2bc5",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1. Загрузите данные. Используйте датасет с ирисами. Его можно загрузить непосредственно из библиотеки Sklearn. В данных оставьте только 2 класса: Iris Versicolor, Iris Virginica.\n",
    "\n",
    "\n",
    "2. Самостоятельно реализуйте логистическую регрессию, без использования метода LogisticRegression из библиотеки. Можете использовать библиотеки pandas, numpy, math для реализации. Оформите в виде функции. *Оформите в виде класса с методами.\n",
    "\n",
    "\n",
    "3. Реализуйте метод градиентного спуска. Обучите логистическую регрессию этим методом. Выберете и посчитайте метрику качества. Метрика должна быть одинакова для всех пунктов домашнего задания. Для упрощения сравнения выберете только одну метрику.\n",
    "\n",
    "\n",
    "4. Повторите п. 3 для метода скользящего среднего (Root Mean Square Propagation, RMSProp).\n",
    "\n",
    "\n",
    "5. Повторите п. 3 для ускоренного по Нестерову метода адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam).\n",
    "\n",
    "\n",
    "6. Сравните значение метрик для реализованных методов оптимизации. Можно оформить в виде таблицы вида |метод|метрика|время работы| (время работы опционально). Напишите вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "945a74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем значение случайности порядка строк\n",
    "np.random.seed(1)\n",
    "\n",
    "#Заводим датасет в датафрейм\n",
    "iris_df = pd.DataFrame(iris.data)\n",
    "iris_df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "iris_df['target'] = pd.DataFrame(iris.target)\n",
    "two_class = iris_df[(iris_df['target'] == 1) | (iris_df['target'] == 2)] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf95762",
   "metadata": {},
   "source": [
    "Опытным путем было установлено, что если оставить target  в виде 1 и 2, то качество обучения резко снижается.А вот если вместо 1 и 2 будет 0 и 1, то все меняется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "a91040a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-601-07cba915276b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  two_class['target'] = two_class['target'].map(mapping)\n"
     ]
    }
   ],
   "source": [
    "mapping = {2:1,1:0}\n",
    "two_class['target'] = two_class['target'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "792b22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверяем, какие у нас теперь есть классы:\n",
    "two_class['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "a3e85fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вот тут загадка лично для меня. если не сделать перемешивание порядка строк, то обучение не работает.\n",
    "data  = two_class.sample(frac=1)\n",
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "y = y[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "11dca50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем наши данные на тренировочную и тестовую выборки (80% - тренировка, 20% - тест):\n",
    "\n",
    "train_X ,test_X = X[:80,:],X[80:,:]\n",
    "train_y ,test_y = y[:80,:],y[80:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "e1652d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#заводим функцию сигмоиды\n",
    "def sigmoid(z) : \n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbf577",
   "metadata": {},
   "source": [
    "Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "725fd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m = train_X.shape[0] # количество строк тренировочной выборки\n",
    "m_test = test_X.shape[0] # количество строк тестовой выборки\n",
    "\n",
    "#добавим колонку со смещением\n",
    "train_X = np.hstack(( np.ones((m,1)) ,train_X)) \n",
    "test_X = np.hstack(( np.ones((m_test,1)) ,test_X))\n",
    "\n",
    "# укажем количество искомых классов\n",
    "k = 2\n",
    "n =train_X.shape[1]\n",
    "\n",
    "# вводим Тету\n",
    "theta = np.zeros((n,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "025d7ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.argmax(test_X @ theta, axis=1) \n",
    "accuracy = np.mean(prediction == test_y.flatten()) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe0d468",
   "metadata": {},
   "source": [
    "Так себе обучилась. теперь попробуем оптимизировать, введя градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "3846c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим функцию потерь \n",
    "def costFunction(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X @ theta)\n",
    "    temp1 = np.multiply(y,np.log(h))\n",
    "    temp2 =np.multiply( (1 - y), np.log(1 - h))\n",
    "    cost = -(1/m)* np.sum(temp1 + temp2) \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a676b1",
   "metadata": {},
   "source": [
    "Добавим функцию градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "3586e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta,X,y):\n",
    "    m = X.shape[0]\n",
    "    temp = sigmoid(np.dot(X, theta)) - y\n",
    "    grad = np.dot(temp.T, X).T / m\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b3b58",
   "metadata": {},
   "source": [
    "А теперь прогоняем через градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "22aa0e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.059522\n",
      "         Iterations: 100\n",
      "         Function evaluations: 268\n",
      "         Gradient evaluations: 268\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.059519\n",
      "         Iterations: 81\n",
      "         Function evaluations: 224\n",
      "         Gradient evaluations: 224\n"
     ]
    }
   ],
   "source": [
    "for i in range(k) :\n",
    "    theta[:,i] = opt.fmin_cg(\n",
    "        f=costFunction,\n",
    "        fprime = gradient, # если честно, здесь можгно было обойтись и без градиента, добавив просто train_X вместо и результат был бы не хуже\n",
    "        x0=theta[:,i],\n",
    "        args=(train_X,(train_y == i).flatten()),\n",
    "        maxiter=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "c7e8ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.argmax(test_X @ theta, axis=1) \n",
    "accuracy = np.mean(prediction == test_y.flatten()) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34726e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c25c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f3371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320da01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4313552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e489c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f7b28106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "d1869f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NM(X, gamma=0.9, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "d5da46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(X, idx):\n",
    "    idx_min = floor(idx)\n",
    "    idx_max = ceil(idx)\n",
    "    if idx_min == idx_max or idx_max >= len(X):\n",
    "        return X[idx_min]\n",
    "    elif idx_min < 0:\n",
    "        return X[idx_max]\n",
    "    else:\n",
    "        return X[idx_min] + (idx - idx_min)*X[idx_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(X, idx):\n",
    "    idx_min = floor(idx)\n",
    "    idx_max = ceil(idx)\n",
    "    if idx_min == idx_max or idx_max >= len(X):\n",
    "        return X[idx_min]\n",
    "    elif idx_min < 0:\n",
    "        return X[idx_max]\n",
    "    else:\n",
    "        return X[idx_min] + (idx - idx_min)*X[idx_max]\n",
    "# Y1 = []\n",
    "def NM(X, gamma=0.9, lr=0.25):\n",
    "    v = 0\n",
    "    Y1 = []\n",
    "    for i in range(len(X)):\n",
    "        v = gamma*v + lr*(linear_interpolation(X, i+gamma*v) if i+gamma*v < len(X) else 0)\n",
    "        Y1.append(v)\n",
    "    return np.asarray(Y1)\n",
    "NM(train_X, gamma=0.9, lr=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
